{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad58771c",
      "metadata": {
        "id": "ad58771c"
      },
      "source": [
        "Author: Justin Braun\n",
        "\n",
        "Date: 20221119\n",
        "\n",
        "Purpose: Generate input data for experiment based on ini config files. Loops over all ini files in '../conf' and outputs single csv file with combinations and sliced data. Combinations data is a copy of the training/synthetic data for each possible combination of values in the variable_list, which are not in violation of the business rule.  'data_generator()' in the final cell calls all other functions.\n",
        "\n",
        "Also note that some combinations between variables we are interested in may violate business rules. These combinations can be removed from the data by specifying them in 'excluded_combinations' in the ini file.\n",
        "\n",
        "Final point, in Data Generator, look for \"CHECK\" comments and specify file paths and whether you have access to the real training data which is not publicly available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f42b56f",
      "metadata": {
        "id": "3f42b56f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import configparser\n",
        "import ast\n",
        "import os\n",
        "import random\n",
        "import copy\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62450350",
      "metadata": {
        "id": "62450350"
      },
      "source": [
        "## Load Config File"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "random.seed = 42"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufh61irP1rSx",
        "outputId": "ac56120d-f744-4848-b9bd-39aa638a0e43"
      },
      "id": "ufh61irP1rSx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675f8bd6",
      "metadata": {
        "id": "675f8bd6"
      },
      "outputs": [],
      "source": [
        "def read_config(conf_path):\n",
        "    #read config file\n",
        "    config = configparser.ConfigParser(allow_no_value=True)\n",
        "    config.read(conf_path)\n",
        "\n",
        "    conf = {} #set up conf dictionary\n",
        "\n",
        "    #load meta data\n",
        "    meta = config['META']\n",
        "    conf['user'] = meta['user']\n",
        "    conf['date'] = meta['date']\n",
        "    conf['name'] = meta['name']\n",
        "\n",
        "    #generate destination file path (where the output csv will be saved)\n",
        "    conf['dest_filename'] = '/content/drive/MyDrive/TnV-2nd_proj/sm_data/output/age/'+conf['date']+'_'+conf['user']+'_'+conf['name']+'.csv'\n",
        "    print('Destination Filename: ' + conf['dest_filename'])\n",
        "\n",
        "    #generate input filepaths for real and synthetic data\n",
        "    filepaths = config['FILEPATHS']\n",
        "    conf['real_fp'] = filepaths['real']\n",
        "    conf['synth_fp'] = filepaths['synth']\n",
        "    print('Real Source FP: '+ conf['real_fp'])\n",
        "    print('Synth Source FP: '+ conf['synth_fp'])\n",
        "\n",
        "    #store variable list as list of lists of dictionaries\n",
        "    variables = config['VARIABLES']\n",
        "    variable_list = variables['variable_list']\n",
        "    variable_list = variable_list.replace('“', '\"')\n",
        "    variable_list = variable_list.replace('”', '\"')\n",
        "    conf['variable_list'] = ast.literal_eval(variable_list) #evaluate string to list of lists of dictionaries\n",
        "    print('Variable list:')\n",
        "    print(conf['variable_list'])\n",
        "\n",
        "    excluded_combinations = variables['excluded_combinations']\n",
        "    conf['excluded_combinations'] = ast.literal_eval(excluded_combinations)\n",
        "    print('Excluded combinations:')\n",
        "    print(conf['excluded_combinations'])\n",
        "    return conf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2efb07c",
      "metadata": {
        "id": "e2efb07c"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827ae6ab",
      "metadata": {
        "id": "827ae6ab"
      },
      "outputs": [],
      "source": [
        "def load_data(fp):\n",
        "    #CHECK: if you are running this code on a Windows machine, you may have to include the argument \"encoding = 'latin'\"\n",
        "    df = pd.read_csv(fp)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05eca36d",
      "metadata": {
        "id": "05eca36d"
      },
      "source": [
        "## Check User Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b28e4c92",
      "metadata": {
        "id": "b28e4c92"
      },
      "outputs": [],
      "source": [
        "def check_user_inputs(td, variable_list):\n",
        "    col_names = list(td.columns.values) #all column names\n",
        "    for nested_list in variable_list:\n",
        "        for dic in nested_list:\n",
        "            #print(dic)\n",
        "            var = list(dic.keys())[0] #var name in variable_list\n",
        "            assert_message = var + ' is not a column name.' #warning message if variable name is not contained in td\n",
        "\n",
        "            #assert that user inputs actually correspond to variables in td\n",
        "            assert var in col_names, assert_message\n",
        "\n",
        "            #if variable values are specified as 'ALL', change to all unique values for this variable\n",
        "            if (dic[var] == ['ALL']):\n",
        "                dic[var] = list(td[var].unique())\n",
        "            dic[var] = list(map(pd.to_numeric, dic[var]))\n",
        "    print('All chosen variables correspondond to columns in the dataset')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef4fda38",
      "metadata": {
        "id": "ef4fda38"
      },
      "source": [
        "## Slice Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8d18699",
      "metadata": {
        "id": "a8d18699"
      },
      "outputs": [],
      "source": [
        "def slice_data(df, variable_list, dt):\n",
        "    df_copy = copy.deepcopy(df) #make a copy of the original df\n",
        "\n",
        "    for nested_list in variable_list:\n",
        "        for dic in nested_list:\n",
        "            var = list(dic.keys())[0]\n",
        "            df_copy = df_copy.loc[df_copy[var].isin(dic[var])] #subset df_copy by values for each variable\n",
        "\n",
        "    df_copy['data_type'] = dt #set data_type column\n",
        "    print(dt + ' copied, shape: ' + str(df_copy.shape))\n",
        "    return df_copy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307a1bc4",
      "metadata": {
        "id": "307a1bc4"
      },
      "source": [
        "## Business Rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0122d60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0122d60",
        "outputId": "c9491281-8c85-477c-bd24-0fbdb0702191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     True\n",
            "1     True\n",
            "2     True\n",
            "3    False\n",
            "4    False\n",
            "5    False\n",
            "6    False\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "def zero_one_hot_encoding_is_valid(column_names, data):\n",
        "    temp=data.loc[:, column_names]\n",
        "    is_zero_or_one_hot_encoded = (temp.sum(axis=1) <= 1)\n",
        "    return is_zero_or_one_hot_encoded\n",
        "\n",
        "#test\n",
        "data = [[0,0],[0,1],[1,0],[1,1],[1,2],[2,1],[2,2]]\n",
        "test_df = pd.DataFrame(data, columns=['refcol', 'col1'])\n",
        "test_fn = zero_one_hot_encoding_is_valid(['col1', 'refcol'], test_df)\n",
        "print(test_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9676a29f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9676a29f",
        "outputId": "9c6e39ab-1aaa-495c-90c6-16d217c87945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     True\n",
            "1    False\n",
            "2     True\n",
            "3     True\n",
            "4    False\n",
            "5     True\n",
            "6     True\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "def zero_or_ge_is_valid(column_names, data, ref_column):\n",
        "    ret_list = [True for i in range(len(data.index))]\n",
        "    for col in column_names:\n",
        "        temp_list = (data[ref_column] >= data[col])\n",
        "        ret_list = temp_list & ret_list\n",
        "    return ret_list\n",
        "\n",
        "#test\n",
        "data = [[0,0],[0,1],[1,0],[1,1],[1,2],[2,1],[2,2]]\n",
        "test_df = pd.DataFrame(data, columns=['refcol', 'col1'])\n",
        "test_fn = zero_or_ge_is_valid(['col1'], test_df, 'refcol')\n",
        "print(test_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b99d92b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b99d92b",
        "outputId": "34cfdedf-42c0-4f14-a986-e4b75a95493e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     True\n",
            "1    False\n",
            "2     True\n",
            "3     True\n",
            "4     True\n",
            "5     True\n",
            "6     True\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "def zero_must_match_is_valid(column_names, data, ref_column):\n",
        "    ret_list = [True for i in range(len(data.index))]\n",
        "    for col in column_names:\n",
        "        temp_list = (((data[ref_column] == 0) & (data[col] == 0)) | (data[ref_column] > 0))\n",
        "        ret_list = temp_list & ret_list\n",
        "    return ret_list\n",
        "\n",
        "#test function\n",
        "data = [[0,0],[0,1],[1,0],[1,1],[1,2],[2,1],[2,2]]\n",
        "test_df = pd.DataFrame(data, columns=['refcol', 'col1'])\n",
        "test_fn = zero_must_match_is_valid(['col1'], test_df, 'refcol')\n",
        "print(test_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd746aa4",
      "metadata": {
        "id": "fd746aa4"
      },
      "source": [
        "## Check Business Rules Violations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa44072",
      "metadata": {
        "id": "4aa44072"
      },
      "outputs": [],
      "source": [
        "def check_bus_rules_violations(comb_list):\n",
        "\n",
        "    #initialize bool_list, which is used to subset the dataframes in comb_list\n",
        "    df = comb_list[0]\n",
        "    bool_list = pd.Series(True, index=df.index) #initialize to all true\n",
        "\n",
        "    #for each dataframe, check if any of the business rules is violated\n",
        "    for index in range(len(comb_list)):\n",
        "        df = comb_list[index] #extract dataframe\n",
        "\n",
        "        district_vars = ['adres_recentste_wijk_charlois', 'adres_recentste_wijk_delfshaven', 'adres_recentste_wijk_feijenoord',\n",
        "                   'adres_recentste_wijk_ijsselmonde', 'adres_recentste_wijk_kralingen_c', 'adres_recentste_wijk_noord',\n",
        "                   'adres_recentste_wijk_other', 'adres_recentste_wijk_prins_alexa', 'adres_recentste_wijk_stadscentru']\n",
        "\n",
        "        bool_list = (zero_one_hot_encoding_is_valid(district_vars, df) & bool_list)\n",
        "        #print('1: ', bool_list.value_counts())\n",
        "\n",
        "        neighborhood_vars = ['adres_recentste_buurt_groot_ijsselmonde', 'adres_recentste_buurt_nieuwe_westen', 'adres_recentste_buurt_other',\n",
        "                   'adres_recentste_buurt_oude_noorden', 'adres_recentste_buurt_vreewijk']\n",
        "\n",
        "        bool_list = (zero_one_hot_encoding_is_valid(neighborhood_vars, df) & bool_list)\n",
        "        #print('2: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_one_hot_encoding_is_valid(['adres_recentste_plaats_other','adres_recentste_plaats_rotterdam'], df) & bool_list)\n",
        "        #print('3: ', bool_list.value_counts())\n",
        "\n",
        "        district_neighborhood_plaats = district_vars + neighborhood_vars + ['adres_recentste_plaats_rotterdam']\n",
        "        district_neighborhood_plaats = list(set(district_neighborhood_plaats) - set(['adres_recentste_wijk_delfshaven', 'adres_recentste_wijk_other', 'adres_recentste_buurt_other']))\n",
        "        bool_list = (zero_or_ge_is_valid(district_neighborhood_plaats, df, 'adres_recentst_onderdeel_rdam') & bool_list)\n",
        "        #print('4: ', bool_list.value_counts())\n",
        "\n",
        "        district_neighborhood_plaats.remove('adres_recentste_plaats_rotterdam')\n",
        "        district_neighborhood = district_neighborhood_plaats\n",
        "        bool_list = (zero_or_ge_is_valid(district_neighborhood, df, 'adres_recentste_plaats_rotterdam') & bool_list)\n",
        "        #print('5: ', bool_list.value_counts())\n",
        "\n",
        "        district_neighborhood_matches = {'adres_recentste_wijk_noord':'adres_recentste_buurt_oude_noorden',\n",
        "                                'adres_recentste_wijk_feijenoord':'adres_recentste_buurt_vreewijk',\n",
        "                                'adres_recentste_wijk_ijsselmonde':'adres_recentste_buurt_groot_ijsselmonde',\n",
        "                                'adres_recentste_wijk_delfshaven':'adres_recentste_buurt_nieuwe_westen'}\n",
        "        for key, value in district_neighborhood_matches.items():\n",
        "            bool_list = (zero_or_ge_is_valid([value], df, key) & bool_list)\n",
        "            #print('5: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_must_match_is_valid(['adres_recentste_wijk_other'], df, 'adres_recentste_buurt_other') & bool_list)\n",
        "        #print('6: ', bool_list.value_counts())\n",
        "\n",
        "        reading_vars = ['persoonlijke_eigenschappen_nl_lezen3', 'persoonlijke_eigenschappen_nl_lezen4']\n",
        "        bool_list = (zero_one_hot_encoding_is_valid(reading_vars, df) & bool_list)\n",
        "        #print('7: ', bool_list.value_counts())\n",
        "\n",
        "        writing_vars = ['persoonlijke_eigenschappen_nl_schrijven0', 'persoonlijke_eigenschappen_nl_schrijven1', 'persoonlijke_eigenschappen_nl_schrijven2',\n",
        "                'persoonlijke_eigenschappen_nl_schrijven3', 'persoonlijke_eigenschappen_nl_schrijvenfalse']\n",
        "        bool_list = (zero_one_hot_encoding_is_valid(writing_vars, df) & bool_list)\n",
        "        #print('8: ', bool_list.value_counts())\n",
        "\n",
        "        speaking_vars = ['persoonlijke_eigenschappen_nl_spreken1', 'persoonlijke_eigenschappen_nl_spreken2',\n",
        "           'persoonlijke_eigenschappen_nl_spreken3']\n",
        "        bool_list = (zero_one_hot_encoding_is_valid(speaking_vars, df) & bool_list)\n",
        "        #print('9: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_or_ge_is_valid(['afspraak_laatstejaar_aantal_woorden'], df, 'afspraak_aantal_woorden') & bool_list)\n",
        "        #print('10: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_or_ge_is_valid(['afspraak_laatstejaar_resultaat_ingevuld_uniek'], df, 'afspraak_resultaat_ingevuld_uniek') & bool_list)\n",
        "        #print('11: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_or_ge_is_valid(['beschikbaarheid_huidig_afwijkend_wegens_medische_omstandigheden'], df, 'beschikbaarheid_huidig_bekend') & bool_list)\n",
        "        #print('12: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_or_ge_is_valid(['beschikbaarheid_recent_afwijkend_wegens_medische_omstandigheden', 'beschikbaarheid_huidig_afwijkend_wegens_medische_omstandigheden'], df, 'beschikbaarheid_aantal_historie_afwijkend_wegens_medische_omstandigheden') & bool_list)\n",
        "        #print('13: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_or_ge_is_valid(['beschikbaarheid_recent_afwijkend_wegens_sociaal_maatschappelijke_situatie'], df, 'beschikbaarheid_aantal_historie_afwijkend_wegens_sociaal_maatschappelijke_situatie') & bool_list)\n",
        "        #print('14: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_one_hot_encoding_is_valid(['beschikbaarheid_recent_afwijkend_wegens_medische_omstandigheden',\n",
        "                                                             'beschikbaarheid_recent_afwijkend_wegens_sociaal_maatschappelijke_situatie'], df) & bool_list)\n",
        "        #print('15: ', bool_list.value_counts())\n",
        "\n",
        "        contacten_matches = {'contacten_onderwerp__arbeids_motivatie':'contacten_onderwerp_boolean__arbeids_motivatie',\n",
        "                 'contacten_onderwerp__pre__intake':'contacten_onderwerp_boolean__pre__intake',\n",
        "                 'contacten_onderwerp__werk_intake':'contacten_onderwerp_boolean__werk_intake',\n",
        "                 'contacten_onderwerp_beoordelen_taaleis':'contacten_onderwerp_boolean_beoordelen_taaleis',\n",
        "                 'contacten_onderwerp_contact_derden':'contacten_onderwerp_boolean_contact_derden',\n",
        "                 'contacten_onderwerp_contact_met_aanbieder':'contacten_onderwerp_boolean_contact_met_aanbieder',\n",
        "                 'contacten_onderwerp_diagnosegesprek':'contacten_onderwerp_boolean_diagnosegesprek',\n",
        "                 'contacten_onderwerp_documenten__innemen_':'contacten_onderwerp_boolean_documenten__innemen_',\n",
        "                 'contacten_onderwerp_documenttype__cv_':'contacten_onderwerp_boolean_documenttype__cv_',\n",
        "                 'contacten_onderwerp_documenttype__overeenkomst_':'contacten_onderwerp_boolean_documenttype__overeenkomst_',\n",
        "                 'contacten_onderwerp_financiële_situatie':'contacten_onderwerp_boolean_financiële_situatie',\n",
        "                 'contacten_onderwerp_groepsbijeenkomst':'contacten_onderwerp_boolean_groepsbijeenkomst',\n",
        "                 'contacten_onderwerp_inkomen':'contacten_onderwerp_boolean_inkomen',\n",
        "                 'contacten_onderwerp_maatregel_overweging':'contacten_onderwerp_boolean_maatregel_overweging',\n",
        "                 'contacten_onderwerp_matching':'contacten_onderwerp_boolean_matching',\n",
        "                 'contacten_onderwerp_mutatie':'contacten_onderwerp_boolean_mutatie',\n",
        "                 'contacten_onderwerp_no_show':'contacten_onderwerp_boolean_no_show',\n",
        "                 'contacten_onderwerp_overige':'contacten_onderwerp_boolean_overige',\n",
        "                 'contacten_onderwerp_overleg_met_inkomen':'contacten_onderwerp_boolean_overleg_met_inkomen',\n",
        "                 'contacten_onderwerp_scholing':'contacten_onderwerp_boolean_scholing',\n",
        "                 'contacten_onderwerp_terugbelverzoek':'contacten_onderwerp_boolean_terugbelverzoek',\n",
        "                 'contacten_onderwerp_traject':'contacten_onderwerp_boolean_traject',\n",
        "                 'contacten_onderwerp_uitnodiging':'contacten_onderwerp_boolean_uitnodiging',\n",
        "                 'contacten_onderwerp_ziek__of_afmelding':'contacten_onderwerp_boolean_ziek__of_afmelding',\n",
        "                 'contacten_onderwerp_zorg':'contacten_onderwerp_boolean_zorg'}\n",
        "        for key, value in contacten_matches.items():\n",
        "            bool_list = (zero_or_ge_is_valid([value], df, key) & bool_list)\n",
        "            #print('16: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_or_ge_is_valid(['relatie_kind_heeft_kinderen'], df, 'relatie_kind_huidige_aantal') & bool_list)\n",
        "        #print('17: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_or_ge_is_valid(['relatie_partner_huidige_partner___partner__gehuwd_'], df, 'relatie_partner_aantal_partner___partner__gehuwd_') & bool_list)\n",
        "        #print('18: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_or_ge_is_valid(['pla_ondertekeningen_actueel'], df, 'pla_ondertekeningen_historie') & bool_list)\n",
        "        #print('19: ', bool_list.value_counts())\n",
        "\n",
        "        ontheffing_vars = ['ontheffing_reden_hist_medische_gronden','ontheffing_reden_hist_other',\n",
        "                   'ontheffing_reden_hist_sociale_gronden',\n",
        "                   'ontheffing_reden_hist_tijdelijke_ontheffing_arbeidsverpl__en_tegenprestatie',\n",
        "                   'ontheffing_reden_hist_tijdelijke_ontheffing_arbeidsverplichtingen',\n",
        "                   'ontheffing_reden_hist_vanwege_uw_sociaal_maatschappelijke_situatie',\n",
        "                   'ontheffing_dagen_hist_vanwege_uw_medische_omstandigheden',\n",
        "                   'ontheffing_dagen_hist_mean']\n",
        "        bool_list = (zero_must_match_is_valid(ontheffing_vars, df, 'ontheffing_hist_ind') & bool_list)\n",
        "        #print('20: ', bool_list.value_counts())\n",
        "\n",
        "        typering_vars = ['typering_indicatie_geheime_gegevens', 'typering_other',\n",
        "                 'typering_transport__logistiek___tuinbouw', 'typering_zorg__schoonmaak___welzijn',\n",
        "                 'typering_aantal', 'typering_ind', 'typering_hist_inburgeringsbehoeftig',\n",
        "                 'typering_hist_sector_zorg', 'typering_dagen_som']\n",
        "        bool_list = (zero_must_match_is_valid(typering_vars, df, 'typering_hist_ind') & bool_list)\n",
        "        #print('21: ', bool_list.value_counts())\n",
        "\n",
        "        bool_list = (zero_or_ge_is_valid(['typering_hist_ind'], df, 'typering_hist_aantal') & bool_list)\n",
        "        #print('22: ', bool_list.value_counts())\n",
        "    #print number of rows which are in violation of business rules\n",
        "    print('Number of rows matching business rules:\\n', str(bool_list.value_counts()))\n",
        "\n",
        "    #exclude rows which are in violation of any business rule from all datafranes in comb_list\n",
        "    for index in range(len(comb_list)):\n",
        "        df = comb_list[index]\n",
        "        df = df[bool_list.values]\n",
        "        comb_list[index] = df\n",
        "\n",
        "    return comb_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ef239be",
      "metadata": {
        "id": "6ef239be"
      },
      "source": [
        "## Generate Combinations Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb935405",
      "metadata": {
        "id": "bb935405"
      },
      "outputs": [],
      "source": [
        "def check_excluded_combinations(comb_list, excluded_combinations):\n",
        "    print('Length comb_list before exclusion: ' + str(len(comb_list)))\n",
        "    temp_list = []\n",
        "    for df in comb_list: #iterate over dataframes\n",
        "        include = True\n",
        "        for dic in excluded_combinations: #iterate over dictionaries specifying exclusion restrictions\n",
        "            exclude = True\n",
        "            for key in dic:\n",
        "                if (df[key].values[0] != int(dic[key])): #case: an exclusion restriction is violated, i.e., the df doesn't need to be removed\n",
        "                    exclude = False\n",
        "                    break\n",
        "            if exclude:\n",
        "                include = False\n",
        "                break\n",
        "        if include: #case: no exclusion restriction has been violated, the df can stay\n",
        "            temp_list.append(df)\n",
        "    print('Length of comb_list after exclusion: ' + str(len(temp_list)))\n",
        "    return temp_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50c7d9d2",
      "metadata": {
        "id": "50c7d9d2"
      },
      "outputs": [],
      "source": [
        "def concat_combinations(new_data, variable_list, excluded_combinations):\n",
        "    comb_list = [new_data] #put new_data into a list\n",
        "\n",
        "    #each nested list corresponds to a single 'feature'. This can either be a single variable or multiple One Hot Encoded vars\n",
        "    #iterate over nested lists\n",
        "    for nested_list in variable_list:\n",
        "        #Hot One encoded case\n",
        "        if len(nested_list) > 1:\n",
        "\n",
        "            #extract all variable names which are OHE\n",
        "            OHE_vars = []\n",
        "            for dic in nested_list:\n",
        "                OHE_vars.append(list(dic.keys())[0])\n",
        "            #set all OHE vars to zero\n",
        "            for df in comb_list:\n",
        "                df.loc[:, OHE_vars] = 0\n",
        "\n",
        "            #for each OHE var create a copy of comb_list and set the var to 1\n",
        "            comb_list_temp = []\n",
        "            for cur_var in OHE_vars:\n",
        "                temp = copy.deepcopy(comb_list)\n",
        "                for df in temp:\n",
        "                    df[cur_var] = 1\n",
        "                comb_list_temp = comb_list_temp + temp\n",
        "\n",
        "            #set comb_list equal to all the newly created copies\n",
        "            comb_list = comb_list_temp\n",
        "\n",
        "        #Single variable case\n",
        "        else:\n",
        "            dic = nested_list[0]\n",
        "            var = list(dic.keys())[0] #extract var name\n",
        "            vals = dic[var] #get values for the variable\n",
        "\n",
        "            #if a variable has more than 20 unique values, take a random sample of those values.\n",
        "            if len(vals) > 20:\n",
        "                random.seed(1)\n",
        "                vals = random.sample(vals, 20)\n",
        "\n",
        "            #for each value, create a copy of comb_list and set var equal to value\n",
        "            comb_list_temp = []\n",
        "            for value in vals:\n",
        "                temp = copy.deepcopy(comb_list)\n",
        "                for df in temp:\n",
        "                    df[var] = value\n",
        "                comb_list_temp = comb_list_temp + temp\n",
        "\n",
        "            #set comb_list equal to all the newly created copies\n",
        "            comb_list = comb_list_temp\n",
        "\n",
        "    #exclude prohibited combinations of specified features\n",
        "    comb_list = check_excluded_combinations(comb_list, excluded_combinations)\n",
        "\n",
        "    #exclude cases which violate business rules\n",
        "    comb_list = check_bus_rules_violations(comb_list)\n",
        "\n",
        "    #set new_data equal to all the possible combinations\n",
        "    new_data = pd.concat(comb_list)\n",
        "\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "557265d4",
      "metadata": {
        "id": "557265d4"
      },
      "outputs": [],
      "source": [
        "def combine_varlist(df, variable_list, excluded_combinations, data_type):\n",
        "    df = concat_combinations(df.copy(), variable_list, excluded_combinations)\n",
        "    df['data_type'] = data_type #specify data_type\n",
        "    print(data_type + ' shape: ' + str(df.shape))\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52bb4a7e",
      "metadata": {
        "id": "52bb4a7e"
      },
      "source": [
        "## Save Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc6c9e59",
      "metadata": {
        "id": "dc6c9e59"
      },
      "outputs": [],
      "source": [
        "def save_data(data_files, dest_filename):\n",
        "    data_exp = pd.concat(data_files) #concatenate data_files\n",
        "    print('Final data shape: ' + str(data_exp.shape)) #print out shape of concatenated dataframe\n",
        "    data_exp.to_csv(dest_filename, index = False) #save\n",
        "    print('Data has been saved to ' + dest_filename) #print save message"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e461e4b6",
      "metadata": {
        "id": "e461e4b6"
      },
      "source": [
        "## Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca257e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dca257e5",
        "outputId": "dcbbdfbf-a9f3-4bae-a374-f5d3c78d24a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading: /content/drive/MyDrive/TnV-2nd_proj/sm_data/archetypes/ethnicity/non_dutch.ini\n",
            "Destination Filename: /content/drive/MyDrive/TnV-2nd_proj/sm_data/output/age/20240416_kgar_non_dutch_5.csv\n",
            "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
            "Synth Source FP: /content/drive/MyDrive/TnV-2nd_proj/sm_data/01_raw/synth_data.csv\n",
            "Variable list:\n",
            "[[{'persoonlijke_eigenschappen_spreektaal_anders': ['1']}], [{'persoonlijke_eigenschappen_nl_schrijvenfalse': ['0']}], [{'persoonlijke_eigenschappen_taaleis_voldaan': ['1']}], [{'contacten_onderwerp_boolean_taaleis___voldoet': ['1']}], [{'belemmering_hist_taal': ['1']}], [{'adres_recentste_wijk_stadscentru': ['0']}]]\n",
            "Excluded combinations:\n",
            "[]\n",
            "All chosen variables correspondond to columns in the dataset\n",
            "synth copied, shape: (103, 316)\n",
            "Length comb_list before exclusion: 1\n",
            "Length of comb_list after exclusion: 1\n",
            "Number of rows matching business rules:\n",
            " True     12508\n",
            "False      137\n",
            "Name: count, dtype: int64\n",
            "synth_conditional shape: (12508, 316)\n",
            "Final data shape: (12611, 316)\n",
            "Data has been saved to /content/drive/MyDrive/TnV-2nd_proj/sm_data/output/age/20240416_kgar_non_dutch_5.csv\n",
            "\n",
            "Reading: /content/drive/MyDrive/TnV-2nd_proj/sm_data/archetypes/ethnicity/very_dutch.ini\n",
            "Destination Filename: /content/drive/MyDrive/TnV-2nd_proj/sm_data/output/age/20240416_kgar_very_dutch_5.csv\n",
            "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
            "Synth Source FP: /content/drive/MyDrive/TnV-2nd_proj/sm_data/01_raw/synth_data.csv\n",
            "Variable list:\n",
            "[[{'persoonlijke_eigenschappen_spreektaal_anders': ['0']}], [{'persoonlijke_eigenschappen_nl_schrijvenfalse': ['0']}], [{'persoonlijke_eigenschappen_taaleis_voldaan': ['1']}], [{'contacten_onderwerp_boolean_taaleis___voldoet': ['1']}], [{'belemmering_hist_taal': ['0']}], [{'adres_recentste_wijk_stadscentru': ['1']}]]\n",
            "Excluded combinations:\n",
            "[]\n",
            "All chosen variables correspondond to columns in the dataset\n",
            "synth copied, shape: (17, 316)\n",
            "Length comb_list before exclusion: 1\n",
            "Length of comb_list after exclusion: 1\n",
            "Number of rows matching business rules:\n",
            " False    9028\n",
            "True     3617\n",
            "Name: count, dtype: int64\n",
            "synth_conditional shape: (3617, 316)\n",
            "Final data shape: (3634, 316)\n",
            "Data has been saved to /content/drive/MyDrive/TnV-2nd_proj/sm_data/output/age/20240416_kgar_very_dutch_5.csv\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#CHECK: set flag depending on whether you have access to the real training data\n",
        "training_access = False\n",
        "\n",
        "def data_generator():\n",
        "    directory_in_str = '/content/drive/MyDrive/TnV-2nd_proj/sm_data/archetypes/ethnicity' #CHECK: file path of ini files\n",
        "    directory = os.fsencode(directory_in_str)\n",
        "\n",
        "\n",
        "    #iterate over all ini config files\n",
        "    for file in os.listdir(directory):\n",
        "        filename = directory_in_str + \"/\" + os.fsdecode(file)\n",
        "\n",
        "        #only load ini files\n",
        "        if not filename.endswith('.ini'):\n",
        "            continue\n",
        "        print('Reading: ' + filename)\n",
        "\n",
        "        #read ini file\n",
        "        conf = read_config(filename)\n",
        "\n",
        "        #load synthetic and real data\n",
        "        if training_access:\n",
        "            real = load_data(conf['real_fp'])\n",
        "        synth = load_data(conf['synth_fp'])\n",
        "\n",
        "        #check user inputs\n",
        "        check_user_inputs(synth, conf['variable_list'])\n",
        "\n",
        "        #generate copy of real data for simple statistical parity test\n",
        "        if training_access:\n",
        "            real_exp = slice_data(real, conf['variable_list'], 'real')\n",
        "        synth_exp = slice_data(synth, conf['variable_list'], 'synth')\n",
        "\n",
        "        #generate data for conditional statistical parity test\n",
        "        if training_access:\n",
        "            real_comb = combine_varlist(real, conf['variable_list'], conf['excluded_combinations'], 'real_conditional')\n",
        "            if real_comb.empty:\n",
        "                raise Exception('Real Combinations Dataframe is empty! You might want to specify excluded combinations in the config file...')\n",
        "        synth_comb = combine_varlist(synth, conf['variable_list'], conf['excluded_combinations'], 'synth_conditional')\n",
        "        if synth_comb.empty:\n",
        "            raise Exception('Synth Combinations Dataframe is empty! You might want to specify excluded combinations in the config file...')\n",
        "\n",
        "        if training_access:\n",
        "            save_data([real_exp, real_comb, synth_exp, synth_comb], conf['dest_filename'])\n",
        "        else:\n",
        "            save_data([synth_exp, synth_comb], conf['dest_filename'])\n",
        "        print()\n",
        "\n",
        "data_generator()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old vs Young"
      ],
      "metadata": {
        "id": "4_3IsQHpa1_z"
      },
      "id": "4_3IsQHpa1_z"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dAJDRhoHbLBX"
      },
      "id": "dAJDRhoHbLBX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}